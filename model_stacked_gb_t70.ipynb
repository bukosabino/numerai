{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Model used by Bukosabino in the Tournament 70 of Numer.ai\n",
    "\n",
    "Results:\n",
    "Logloss: 0.69199 - Consistency: 75% - Originality: Yes - Concordance: Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics, preprocessing, linear_model, svm, ensemble\n",
    "from sklearn.base import BaseEstimator,TransformerMixin, ClassifierMixin\n",
    "from sklearn.decomposition import *\n",
    "from sklearn.manifold import *\n",
    "from sklearn.random_projection import *\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.utils import check_array\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "SUBMISSION = False #Â change to True if you want generate output.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class StackingEstimator(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, estimator):\n",
    "        self.estimator = estimator\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        self.estimator.fit(X, y, **fit_params)\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = check_array(X)\n",
    "        X_transformed = np.copy(X)\n",
    "        # add class probabilities as a synthetic feature\n",
    "        if issubclass(self.estimator.__class__, ClassifierMixin) and hasattr(self.estimator, 'predict_proba'):\n",
    "            X_transformed = np.hstack((self.estimator.predict_proba(X), X))\n",
    "\n",
    "        # add class prodiction as a synthetic feature\n",
    "        X_transformed = np.hstack((np.reshape(self.estimator.predict(X), (-1, 1)), X_transformed))\n",
    "\n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# reading data\n",
    "train = pd.read_csv('../data/input70/numerai_training_data.csv', header=0)\n",
    "test = pd.read_csv('../data/input70/numerai_tournament_data.csv', header=0)\n",
    "if not SUBMISSION:\n",
    "    test = test[test.data_type == 'validation'] # only validation\n",
    "\n",
    "features = [f for f in list(train) if \"feature\" in f]\n",
    "X = train[features]\n",
    "Y = train[\"target\"]\n",
    "x_prediction = test[features]\n",
    "ids = test[\"id\"]\n",
    "\n",
    "n_comp = 2\n",
    "grp = GaussianRandomProjection(n_components=n_comp, eps=0.1, random_state=420)\n",
    "grp_results_train = grp.fit_transform(train[features])\n",
    "grp_results_test = grp.transform(test[features])\n",
    "\n",
    "for i in range(1, n_comp + 1):\n",
    "    train['feature_grp_' + str(i)] = grp_results_train[:, i - 1]\n",
    "    test['feature_grp_' + str(i)] = grp_results_test[:, i - 1]\n",
    "    \n",
    "features = [f for f in list(train) if \"feature\" in f]\n",
    "X = train[features]\n",
    "Y = train[\"target\"]\n",
    "x_prediction = test[features]\n",
    "ids = test[\"id\"]\n",
    "\n",
    "stacked_pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=linear_model.LassoLarsCV(normalize=True)),\n",
    "    StackingEstimator(estimator=ensemble.GradientBoostingRegressor(learning_rate=0.001, random_state=2345, loss=\"huber\", max_depth=3, max_features=0.55, min_samples_leaf=18, min_samples_split=14, subsample=0.7)),\n",
    "    linear_model.LassoLarsCV()\n",
    ")\n",
    "stacked_pipeline.fit(X, Y)\n",
    "results_stacked = stacked_pipeline.predict(x_prediction)\n",
    "if not SUBMISSION:\n",
    "    print metrics.log_loss(test[\"target\"], results_stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# reading data\n",
    "train = pd.read_csv('../data/input70/numerai_training_data.csv', header=0)\n",
    "test = pd.read_csv('../data/input70/numerai_tournament_data.csv', header=0)\n",
    "if not SUBMISSION:\n",
    "    test = test[test.data_type == 'validation'] # only validation\n",
    "\n",
    "features = [f for f in list(train) if \"feature\" in f]\n",
    "X = train[features]\n",
    "Y = train[\"target\"]\n",
    "x_prediction = test[features]\n",
    "ids = test[\"id\"]\n",
    "\n",
    "n_comp = 2\n",
    "grp = GaussianRandomProjection(n_components=n_comp, eps=0.1, random_state=420)\n",
    "grp_results_train = grp.fit_transform(train[features])\n",
    "grp_results_test = grp.transform(test[features])\n",
    "\n",
    "for i in range(1, n_comp + 1):\n",
    "    train['feature_grp_' + str(i)] = grp_results_train[:, i - 1]\n",
    "    test['feature_grp_' + str(i)] = grp_results_test[:, i - 1]\n",
    "\n",
    "features = [f for f in list(train) if \"feature\" in f]\n",
    "X_gb = train[features]\n",
    "x_prediction_gb = test[features]\n",
    "\n",
    "n_comp = 2\n",
    "grp = GaussianRandomProjection(n_components=n_comp, eps=0.1, random_state=420)\n",
    "grp_results_train = grp.fit_transform(train[features])\n",
    "grp_results_test = grp.transform(test[features])\n",
    "\n",
    "for i in range(1, n_comp + 1):\n",
    "    train['feature_grp_' + str(i)] = grp_results_train[:, i - 1]\n",
    "    test['feature_grp_' + str(i)] = grp_results_test[:, i - 1]\n",
    "    \n",
    "features = [f for f in list(train) if \"feature\" in f]\n",
    "X_gb = train[features]\n",
    "x_prediction_gb = test[features]\n",
    "\n",
    "model = ensemble.GradientBoostingClassifier(n_estimators=80, max_depth=2, random_state=17)\n",
    "model.fit(X_gb, Y)\n",
    "results_gb = model.predict_proba(x_prediction_gb)[:, 1]\n",
    "if not SUBMISSION:\n",
    "    print metrics.log_loss(test[\"target\"], results_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "result_mean = np.mean(np.array([results_gb, results_stacked]), axis=0)\n",
    "if not SUBMISSION:\n",
    "    print metrics.log_loss(test[\"target\"], result_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if SUBMISSION:\n",
    "    results_df = pd.DataFrame(data={'probability':result_mean})\n",
    "    joined = pd.DataFrame(ids).join(results_df)\n",
    "    joined.to_csv(\"predictions_stacked_gb.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
